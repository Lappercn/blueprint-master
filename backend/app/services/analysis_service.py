# æ–‡ä»¶åï¼šanalysis_service.py
"""
åŠŸèƒ½è¯´æ˜ï¼šè“å›¾åˆ†æä¸šåŠ¡é€»è¾‘æœåŠ¡
æ ¸å¿ƒåŠŸèƒ½ï¼š
1. è°ƒç”¨OCRè¯†åˆ«æ–‡ä»¶å†…å®¹
2. æ„å»ºæç¤ºè¯å·¥ç¨‹
3. è°ƒç”¨LLMè¿›è¡Œæµå¼åˆ†æ
ä¾èµ–æ¨¡å—ï¼šocr_client, llm_client, config
"""
import logging
import re
from typing import Generator, List
from app.config import Config
from app.utils.ocr_client import OCRClient
from app.utils.llm_client import LLMClient

logger = logging.getLogger(__name__)

# å®šä¹‰ç»“æ„åŒ–çš„åœºæ™¯æ–¹æ³•è®ºåº“
METHODOLOGIES_STRUCTURED = {
    "huawei": {
        "label": "åä¸º (Huawei)",
        "scenarios": {
            "strategy": {
                "label": "æˆ˜ç•¥è§„åˆ’å±‚ (Strategy - BLM/BEM)",
                "description": "é€‚ç”¨äºå…¬å¸æˆ˜ç•¥è§£ç ã€é¡¶å±‚è®¾è®¡ã€ä¸šåŠ¡è“å›¾è§„åˆ’ã€‚",
                "content": """
                *   **åä¸ºæˆ˜ç•¥è§„åˆ’æ–¹æ³•è®º** (å‚è€ƒä¹¦ç±ï¼šã€Šä»·å€¼ä¸ºçº²ã€‹ã€ã€Šä»¥å®¢æˆ·ä¸ºä¸­å¿ƒã€‹)ï¼š
                    *   **BLM (Business Leadership Model, ä¸šåŠ¡é¢†å…ˆæ¨¡å‹)**ï¼š
                        *   **å·®è·åˆ†æ**ï¼šä»ä¸šç»©å·®è·ï¼ˆç»“æœï¼‰å’Œæœºä¼šå·®è·ï¼ˆæœªæ¥ï¼‰å…¥æ‰‹ã€‚
                        *   **æˆ˜ç•¥æ„å›¾**ï¼šæ„¿æ™¯ã€æˆ˜ç•¥ç›®æ ‡ã€è¿‘æœŸç›®æ ‡ã€‚
                        *   **å¸‚åœºæ´å¯Ÿ**ï¼šäº”çœ‹ï¼ˆçœ‹è¶‹åŠ¿ã€çœ‹å¸‚åœºã€çœ‹å®¢æˆ·ã€çœ‹ç«äº‰ã€çœ‹è‡ªå·±ï¼‰ã€‚
                        *   **åˆ›æ–°ç„¦ç‚¹**ï¼šæœªæ¥ä¸šåŠ¡ç»„åˆã€åˆ›æ–°æ¨¡å¼ï¼ˆäº§å“/æœåŠ¡/å•†ä¸šæ¨¡å¼ï¼‰ã€‚
                        *   **ä¸šåŠ¡è®¾è®¡**ï¼šå®¢æˆ·é€‰æ‹©ã€ä»·å€¼ä¸»å¼ ã€ç›ˆåˆ©æ¨¡å¼ã€æˆ˜ç•¥æ§åˆ¶ç‚¹ã€é£é™©ç®¡ç†ã€‚
                    *   **BEM (Business Engineering Methodology, ä¸šåŠ¡å·¥ç¨‹æ–¹æ³•)**ï¼šæˆ˜ç•¥è§£ç ï¼Œå°†æˆ˜ç•¥ç›®æ ‡åˆ†è§£ä¸ºå…³é”®ä¸šåŠ¡æŒ‡æ ‡ï¼ˆKPIï¼‰å’Œé‡ç‚¹å·¥ä½œï¼ˆPBCï¼‰ã€‚
                """
            },
            "finance_mgmt": {
                "label": "è´¢ç»ç®¡ç†å±‚ (IFS)",
                "description": "é€‚ç”¨äºè´¢ç»æµç¨‹ã€å…¨é¢é¢„ç®—ç®¡ç†ã€å†…æ§ã€‚",
                "content": """
                *   **åä¸ºIFS (Integrated Financial Services, é›†æˆè´¢ç»æœåŠ¡)** (å‚è€ƒä¹¦ç±ï¼šã€Šåä¸ºè´¢ç»å¯†ç ã€‹)ï¼š
                    *   **ä¸šè´¢èåˆ**ï¼šè´¢ç»åˆ‡å…¥ä¸šåŠ¡å‰ç«¯ï¼Œä»â€œè®°è´¦å‘˜â€è½¬å˜ä¸ºâ€œä¸šåŠ¡ä¼™ä¼´â€ã€‚
                    *   **å…¨é¢é¢„ç®—ç®¡ç†**ï¼šæˆ˜ç•¥å†³å®šé¢„ç®—ï¼Œé¢„ç®—ä¿éšœæˆ˜ç•¥ã€‚
                    *   **é¡¹ç›®å››ç®—**ï¼šæ¦‚ç®—ã€é¢„ç®—ã€æ ¸ç®—ã€å†³ç®—ã€‚
                """
            },
            "marketing": {
                "label": "å¸‚åœºè¥é”€å±‚ (MTL)",
                "description": "é€‚ç”¨äºå¸‚åœºæ´å¯Ÿã€å“ç‰Œç®¡ç†ã€çº¿ç´¢ç”Ÿæˆã€‚",
                "content": """
                *   **åä¸ºMTL (Market to Lead, å¸‚åœºåˆ°çº¿ç´¢)** (å‚è€ƒä¹¦ç±ï¼šã€Šåä¸ºè¥é”€æ³•ã€‹)ï¼š
                    *   **å¸‚åœºæ´å¯Ÿ (MI)**ï¼šç†è§£å®è§‚ç¯å¢ƒã€è¡Œä¸šè¶‹åŠ¿ã€å®¢æˆ·å£°éŸ³ã€‚
                    *   **å¸‚åœºç®¡ç† (MM)**ï¼šç»†åˆ†å¸‚åœºã€ç›®æ ‡å¸‚åœºé€‰æ‹©ã€å®šä½ã€‚
                    *   **æ´»åŠ¨ç®¡ç†**ï¼šé€šè¿‡è¥é”€æ´»åŠ¨ç”Ÿæˆé«˜è´¨é‡é”€å”®çº¿ç´¢ã€‚
                """
            },
            "issue_mgmt": {
                "label": "é—®é¢˜åˆ°è§£å†³å±‚ (ITR)",
                "description": "é€‚ç”¨äºå”®åæœåŠ¡ã€å®¢æˆ·æŠ•è¯‰å¤„ç†ã€è¿ç»´ã€‚",
                "content": """
                *   **åä¸ºITR (Issue to Resolution, é—®é¢˜åˆ°è§£å†³)**ï¼š
                    *   **ç«¯åˆ°ç«¯é—­ç¯**ï¼šå—ç† -> å¤„ç† -> å…³é—­ -> è¯„ä»·ã€‚
                    *   **åˆ†å±‚åˆ†çº§**ï¼šä¸€çº¿å¿«é€Ÿå“åº”ï¼ŒäºŒçº¿ä¸“å®¶æ”¯æŒï¼Œä¸‰çº¿ç ”å‘æ”»å…³ã€‚
                    *   **çŸ¥è¯†æ²‰æ·€**ï¼šå°†é—®é¢˜è½¬åŒ–ä¸ºçŸ¥è¯†åº“ (KB)ï¼Œé¿å…é‡å¤é€ è½®å­ã€‚
                """
            },
            "project_delivery": {
                "label": "é¡¹ç›®äº¤ä»˜/é”€å”®å±‚ (LTC/LTC-P)",
                "description": "é€‚ç”¨äºé”€å”®é¡¹ç›®ç®¡ç†ã€äº¤ä»˜å®æ–½ã€åˆåŒå±¥çº¦ã€‚",
                "content": """
                *   **åä¸ºLTC (Lead to Cash) æµç¨‹** (å‚è€ƒä¹¦ç±ï¼šã€Šåä¸ºè¥é”€æ³•ã€‹ã€ã€Šåä¸ºé“ä¸‰è§’å·¥ä½œæ³•ã€‹)ï¼š
                    *   **ç®¡ç†çº¿ç´¢ (ML)**ï¼šçº¿ç´¢æŒ–æ˜ã€åŸ¹è‚²ã€åˆ†å‘ã€‚
                    *   **ç®¡ç†æœºä¼šç‚¹ (MO)**ï¼šæœºä¼šç‚¹éªŒè¯ã€ç«‹é¡¹ã€æŠ•æ ‡ã€åˆåŒè°ˆåˆ¤ã€‚
                    *   **ç®¡ç†åˆåŒæ‰§è¡Œ (MCE)**ï¼šåˆåŒäº¤æ¥ã€å‘è´§/äº¤ä»˜ã€éªŒæ”¶ã€å›æ¬¾ã€‚
                    *   **é“ä¸‰è§’ç»„ç»‡**ï¼šAR (å®¢æˆ·ç»ç†)ã€SR (è§£å†³æ–¹æ¡ˆç»ç†)ã€FR (äº¤ä»˜ç»ç†) ååŒä½œæˆ˜ã€‚
                """
            },
            "product_dev": {
                "label": "äº§å“ç ”å‘å±‚ (IPD)",
                "description": "é€‚ç”¨äºäº§å“å¼€å‘ã€æŠ€æœ¯æ¶æ„è®¾è®¡ã€ç ”å‘ç®¡ç†ã€‚",
                "content": """
                *   **åä¸ºIPD (Integrated Product Development, é›†æˆäº§å“å¼€å‘)** (å‚è€ƒä¹¦ç±ï¼šã€ŠIPDï¼šåä¸ºç ”å‘ä¹‹é“ã€‹ã€ã€Šåä¸ºç ”å‘ã€‹)ï¼š
                    *   **ç»“æ„åŒ–æµç¨‹**ï¼šæ¦‚å¿µã€è®¡åˆ’ã€å¼€å‘ã€éªŒè¯ã€å‘å¸ƒã€ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚
                    *   **å¼‚æ­¥å¼€å‘**ï¼šæŠ€æœ¯å¼€å‘ä¸äº§å“å¼€å‘åˆ†ç¦»ã€‚
                    *   **è·¨éƒ¨é—¨å›¢é˜Ÿ (PDT)**ï¼šæ‰“ç ´éƒ¨é—¨å¢™ï¼Œå¯¹å•†ä¸šæˆåŠŸè´Ÿè´£ã€‚
                    *   **CBB (Common Building Block)**ï¼šå…±ç”¨åŸºç¡€æ¨¡å—ï¼Œæå‡ç ”å‘æ•ˆç‡ã€‚
                """
            },
            "digital_transformation": {
                "label": "æ•°å­—åŒ–è½¬å‹å±‚ (Digital)",
                "description": "é€‚ç”¨äºä¼ä¸šæ•°å­—åŒ–è½¬å‹è§„åˆ’ã€æ•°æ®æ²»ç†ã€ITæ¶æ„ã€‚",
                "content": """
                *   **åä¸ºæ•°å­—åŒ–è½¬å‹æ–¹æ³•è®º** (å‚è€ƒä¹¦ç±ï¼šã€Šåä¸ºæ•°å­—åŒ–è½¬å‹ä¹‹é“ã€‹)ï¼š
                    *   **1å¥—æ–¹æ³•**ï¼šå¯¹è±¡æ•°å­—åŒ–ã€è¿‡ç¨‹æ•°å­—åŒ–ã€è§„åˆ™æ•°å­—åŒ–ã€‚
                    *   **5è½¬**ï¼šè½¬æ„è¯†ã€è½¬ç»„ç»‡ã€è½¬æ–‡åŒ–ã€è½¬æ–¹æ³•ã€è½¬æ¨¡å¼ã€‚
                    *   **â€œäº”çœ‹ä¸‰å®šâ€**ï¼šçœ‹è¡Œä¸šã€çœ‹å®¢æˆ·ã€çœ‹è‡ªå·±ã€çœ‹æœºä¼šã€çœ‹æŠ€æœ¯ï¼›å®šæˆ˜ç•¥ã€å®šæ¨¡å¼ã€å®šè·¯å¾„ã€‚
                    *   **æ•°æ®åº•åº§**ï¼šæ•°æ®å…¥æ¹–ã€æ•°æ®èµ„äº§åŒ–ã€æ•°æ®æœåŠ¡åŒ–ã€‚
                """
            }
        }
    },
    "general": {
        "label": "é€šç”¨/è¡Œä¸šæ ‡å‡† (General)",
        "scenarios": {
            "enterprise_arch": {
                "label": "ä¼ä¸šæ¶æ„å±‚ (Enterprise Architecture)",
                "description": "é€‚ç”¨äºé¡¶å±‚æ¶æ„è§„åˆ’ã€ä¸šåŠ¡ä¸ITå¯¹é½ã€‚",
                "content": """
                *   **é€šç”¨ä¼ä¸šæ¶æ„æ ‡å‡†** (å‚è€ƒä¹¦ç±ï¼šã€ŠTOGAFæ ‡å‡†ã€‹ã€ã€Šä¼ä¸šæ¶æ„çš„æ•°å­—åŒ–è½¬å‹ã€‹)ï¼š
                    *   **TOGAF (The Open Group Architecture Framework)**ï¼š
                        *   **ADM (Architecture Development Method)**ï¼šæ¶æ„å¼€å‘æ–¹æ³•å¾ªç¯ã€‚
                        *   **4Aæ¶æ„**ï¼šä¸šåŠ¡æ¶æ„ (Business)ã€æ•°æ®æ¶æ„ (Data)ã€åº”ç”¨æ¶æ„ (Application)ã€æŠ€æœ¯æ¶æ„ (Technology)ã€‚
                """
            },
            "it_management": {
                "label": "ITæœåŠ¡ä¸ç®¡ç†å±‚ (IT Management)",
                "description": "é€‚ç”¨äºITè¿ç»´ç®¡ç†ã€æœåŠ¡æµç¨‹è§„èŒƒã€‚",
                "content": """
                *   **é€šç”¨ITç®¡ç†æ ‡å‡†** (å‚è€ƒä¹¦ç±ï¼šã€ŠITIL 4 å®è·µæŒ‡å—ã€‹ã€ã€ŠDevOps å®è·µæŒ‡å—ã€‹)ï¼š
                    *   **ITIL (Information Technology Infrastructure Library)**ï¼šITæœåŠ¡ç®¡ç†æœ€ä½³å®è·µã€‚
                    *   **DevOps**ï¼šå¼€å‘ä¸è¿ç»´èåˆï¼ŒæŒç»­äº¤ä»˜ (CI/CD)ã€‚
                """
            },
            "project_management": {
                "label": "é¡¹ç›®ç®¡ç†å±‚ (Project Management)",
                "description": "é€‚ç”¨äºé€šç”¨é¡¹ç›®ç®¡ç†ã€æ•æ·å¼€å‘ã€‚",
                "content": """
                *   **é€šç”¨é¡¹ç›®ç®¡ç†æ ‡å‡†** (å‚è€ƒä¹¦ç±ï¼šã€ŠPMBOKæŒ‡å—ã€‹ã€ã€ŠScrumç²¾é«“ã€‹)ï¼š
                    *   **PMP/PMBOK**ï¼šäº”å¤§è¿‡ç¨‹ç»„ï¼ˆå¯åŠ¨ã€è§„åˆ’ã€æ‰§è¡Œã€ç›‘æ§ã€æ”¶å°¾ï¼‰ã€åå¤§çŸ¥è¯†é¢†åŸŸã€‚
                    *   **Agile/Scrum**ï¼šæ•æ·å¼€å‘ã€è¿­ä»£å†²åˆºã€æ¯æ—¥ç«™ä¼šã€‚
                """
            }
        }
    },
    "advertising": {
        "label": "å¹¿å‘Šè¥é”€å¤§å¸ˆ (Advertising & Marketing)",
        "scenarios": {
            "positioning": {
                "label": "å®šä½ç†è®º (Positioning)",
                "description": "é€‚ç”¨äºå“ç‰Œå®šä½ã€å¿ƒæ™ºå é¢†ã€‚",
                "content": """
                *   **å®šä½ç†è®º (Positioning)** (å‚è€ƒä¹¦ç±ï¼šã€Šå®šä½ã€‹ã€ã€Šå•†æˆ˜ã€‹ - ç‰¹åŠ³ç‰¹/é‡Œæ–¯)ï¼š
                    *   **å¿ƒæ™ºé˜¶æ¢¯**ï¼šå“ç‰Œåœ¨æ¶ˆè´¹è€…å¿ƒæ™ºä¸­çš„æ’åã€‚
                    *   **å·®å¼‚åŒ–**ï¼šå¯»æ‰¾ç«äº‰å¯¹æ‰‹æ— æ³•å æ®çš„ä¼˜åŠ¿ä½ç½®ã€‚
                    *   **èšç„¦**ï¼šé›†ä¸­èµ„æºæ”»å‡»ä¸€ç‚¹ã€‚
                """
            },
            "integrated_marketing": {
                "label": "æ•´åˆè¥é”€ (IMC)",
                "description": "é€‚ç”¨äºå…¨æ¡ˆç­–åˆ’ã€å“ç‰Œä¼ æ’­ã€‚",
                "content": """
                *   **æ•´åˆè¥é”€ä¼ æ’­ (IMC)** (å‚è€ƒä¹¦ç±ï¼šã€Šæ•´åˆè¥é”€ä¼ æ’­ã€‹ - èˆ’å°”èŒ¨)ï¼š
                    *   **4Cç†è®º**ï¼šæ¶ˆè´¹è€…(Consumer)ã€æˆæœ¬(Cost)ã€ä¾¿åˆ©(Convenience)ã€æ²Ÿé€š(Communication)ã€‚
                    *   **å“ç‰Œæ¥è§¦ç‚¹**ï¼šç®¡ç†æ‰€æœ‰ä¸æ¶ˆè´¹è€…æ¥è§¦çš„ç¯èŠ‚ã€‚
                """
            },
            "creative": {
                "label": "åˆ›æ„ä¸æ–‡æ¡ˆ (Creative)",
                "description": "é€‚ç”¨äºå¹¿å‘Šåˆ›æ„ã€æ–‡æ¡ˆå†™ä½œã€‚",
                "content": """
                *   **å¥¥æ ¼å¨å¹¿å‘Šæ³•åˆ™** (å‚è€ƒä¹¦ç±ï¼šã€Šä¸€ä¸ªå¹¿å‘Šäººçš„è‡ªç™½ã€‹ - å¤§å«Â·å¥¥æ ¼å¨)ï¼š
                    *   **å“ç‰Œå½¢è±¡**ï¼šæ¯ä¸€åˆ™å¹¿å‘Šéƒ½æ˜¯å¯¹å“ç‰Œä¸ªæ€§çš„é•¿æœŸæŠ•èµ„ã€‚
                    *   **å¤§åˆ›æ„ (Big Idea)**ï¼šé™¤éä½ çš„å¹¿å‘ŠåŸºäºä¸€ä¸ªå¤§åˆ›æ„ï¼Œå¦åˆ™å®ƒå°±åƒå¤œèˆªçš„èˆ¹ï¼Œæ— äººçŸ¥æ™“ã€‚
                    *   **é”€å”®åŠ›**ï¼šå¹¿å‘Šçš„ç›®çš„æ˜¯é”€å”®ï¼Œä¸æ˜¯å¨±ä¹ã€‚
                """
            },
            "growth_hacking": {
                "label": "å¢é•¿é»‘å®¢ (Growth)",
                "description": "é€‚ç”¨äºç”¨æˆ·å¢é•¿ã€æµé‡è¿è¥ã€‚",
                "content": """
                *   **å¢é•¿é»‘å®¢** (å‚è€ƒä¹¦ç±ï¼šã€Šå¢é•¿é»‘å®¢ã€‹ - è‚–æ©Â·åŸƒåˆ©æ–¯)ï¼š
                    *   **AARRRæ¨¡å‹**ï¼šè·å–(Acquisition)ã€æ¿€æ´»(Activation)ã€ç•™å­˜(Retention)ã€å˜ç°(Revenue)ã€æ¨è(Referral)ã€‚
                    *   **åŒ—ææ˜ŸæŒ‡æ ‡**ï¼šæŒ‡å¼•å…¨å…¬å¸å‘ç€é•¿æœŸä»·å€¼å¢é•¿æ–¹å‘å‘å±•çš„å”¯ä¸€å…³é”®æŒ‡æ ‡ã€‚
                """
            }
        }
    }
}

class AnalysisService:
    def __init__(self):
        # åˆå§‹åŒ– OCR å®¢æˆ·ç«¯
        self.ocr_client = OCRClient(
            app_id=Config.TEXTIN_APP_ID,
            secret_code=Config.TEXTIN_SECRET_CODE
        )
        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.llm_client = LLMClient(
            api_key=Config.OPENAI_API_KEY,
            base_url=Config.OPENAI_BASE_URL,
            model=Config.LLM_MODEL
        )

    def _compress_methodology_text(self, text: str, max_chars: int) -> str:
        if not text:
            return ""
        normalized = text.replace("\r\n", "\n").replace("\r", "\n")
        normalized = re.sub(r"\n{3,}", "\n\n", normalized)
        if len(normalized) <= max_chars:
            return normalized
        lines = []
        total = 0
        for line in normalized.splitlines():
            s = line.strip()
            keep = (
                s == ""
                or s.startswith("###")
                or s.startswith("*")
                or s.startswith("-")
                or s.startswith("1.")
                or s.startswith("2.")
                or s.startswith("3.")
            )
            if not keep:
                continue
            if total + len(line) + 1 > max_chars:
                break
            lines.append(line)
            total += len(line) + 1
        compact = "\n".join(lines).strip()
        if not compact:
            compact = normalized[:max_chars]
        return compact[:max_chars]

    def _compress_context_text(self, text: str, max_chars: int) -> tuple[str, bool]:
        if not text:
            return "", False

        original_len = len(text)
        t = text.replace("\r\n", "\n").replace("\r", "\n")
        t = re.sub(r"[ \t]+", " ", t)
        t = re.sub(r"\n{3,}", "\n\n", t)
        t = re.sub(r"```[\s\S]{2000,}?```", "```(å·²çœç•¥è¶…é•¿ä»£ç å—)```", t)

        if len(t) <= max_chars:
            return t, len(t) != original_len

        lines = t.splitlines()
        heading_indexes: List[int] = []
        for i, line in enumerate(lines):
            s = line.strip()
            if s.startswith("#"):
                heading_indexes.append(i)

        keep_line_indexes = set()
        for i in heading_indexes[:200]:
            for j in range(i, min(i + 6, len(lines))):
                keep_line_indexes.add(j)

        extracted_lines = [lines[i] for i in range(len(lines)) if i in keep_line_indexes]
        extracted = "\n".join(extracted_lines).strip()

        head = t[:8000]
        tail = t[-2000:] if len(t) > 2000 else ""
        combined = "\n\n".join([p for p in [head.strip(), extracted, tail.strip()] if p])
        combined = re.sub(r"\n{3,}", "\n\n", combined)
        combined = combined[:max_chars]
        return combined, True

    def analyze_blueprint(self, file_content: bytes, file_name: str, custom_prompt: str = "", selected_methodologies: List[str] = None, custom_methodologies: List[str] = None) -> Generator[str, None, None]:
        """
        åˆ†æè“å›¾æ–‡ä»¶
        :param file_content: æ–‡ä»¶å†…å®¹
        :param file_name: æ–‡ä»¶å
        :param custom_prompt: ç”¨æˆ·è‡ªå®šä¹‰æç¤ºè¯
        :param selected_methodologies: ç”¨æˆ·é€‰æ‹©çš„æ–¹æ³•è®ºåˆ—è¡¨ ['huawei', 'alibaba', ...]
        :param custom_methodologies: ç”¨æˆ·è‡ªå®šä¹‰çš„æ–¹æ³•è®ºåˆ—è¡¨
        :return: LLM æµå¼å“åº”ç”Ÿæˆå™¨
        """
        try:
            # 0. å‘é€åˆå§‹çŠ¶æ€ï¼Œç¡®ä¿æµè¿æ¥å»ºç«‹
            yield f"ğŸ”„ æ­£åœ¨è§£ææ–‡æ¡£å†…å®¹ï¼Œè¯·ç¨å€™...\n\n"
            
            # å®šæ—¶å‘é€å¿ƒè·³åŒ…çš„ç”Ÿæˆå™¨å‡½æ•°
            def keep_alive_ocr():
                import time
                while True:
                    time.sleep(2) # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
                    yield f": keep-alive\n\n"

            # 1. OCR è¯†åˆ«
            logger.info(f"Starting OCR for file: {file_name}")
            
            # ç”±äºOCRæ˜¯åŒæ­¥é˜»å¡è°ƒç”¨ï¼Œæˆ‘ä»¬æ— æ³•åœ¨å…¶ä¸­æ’å…¥yieldã€‚
            # å¦‚æœOCRéå¸¸æ…¢ï¼ˆè¶…è¿‡60ç§’ï¼‰ï¼Œä»ç„¶å¯èƒ½å¯¼è‡´è¶…æ—¶ã€‚
            # ç†æƒ³æ–¹æ¡ˆæ˜¯å°†OCRæ”¾å…¥ç‹¬ç«‹çº¿ç¨‹ï¼Œä¸»çº¿ç¨‹yieldå¿ƒè·³ã€‚
            # è¿™é‡Œå…ˆå°è¯•æ›´æ¿€è¿›çš„paddingå’Œæ›´å¿«çš„å“åº”ã€‚
            
            import threading
            import queue
            
            ocr_queue = queue.Queue()
            
            def run_ocr_thread():
                try:
                    text = self.ocr_client.recognize(file_content)
                    ocr_queue.put({"status": "success", "data": text})
                except Exception as e:
                    ocr_queue.put({"status": "error", "error": e})
            
            ocr_thread = threading.Thread(target=run_ocr_thread)
            ocr_thread.start()
            
            # ç­‰å¾…OCRç»“æœï¼ŒæœŸé—´å‘é€å¿ƒè·³
            # ä½¿ç”¨ SSE åè®®æ ‡å‡†çš„æ³¨é‡Šæ ¼å¼ ": comment\n\n"
            # è®¸å¤šä»£ç†æœåŠ¡å™¨ï¼ˆå¦‚Nginxï¼‰éœ€è¦çœ‹åˆ° \n\n æ‰ä¼šåˆ·æ–°ç¼“å†²åŒº
            # ä¸”æ³¨é‡Šè¡Œä»¥å†’å·å¼€å¤´æ˜¯ SSE è§„èŒƒï¼Œé¿å…å‰ç«¯è§£æé”™è¯¯
            while ocr_thread.is_alive():
                ocr_thread.join(timeout=2.0) # æ¯2ç§’é†’æ¥ä¸€æ¬¡
                if ocr_thread.is_alive():
                     yield f": processing ocr keep-alive\n\n" 
            
            # è·å–ç»“æœ
            if not ocr_queue.empty():
                result = ocr_queue.get()
                if result["status"] == "error":
                     raise result["error"]
                ocr_text = result["data"]
            else:
                ocr_text = ""
            
            logger.info(f"OCR result length: {len(ocr_text) if ocr_text else 0}")

            if not ocr_text or len(ocr_text.strip()) == 0:
                logger.warning("OCR returned empty text")
                yield "æ— æ³•è¯†åˆ«æ–‡ä»¶å†…å®¹ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ¸…æ™°æˆ–æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
                return

            logger.info("OCR completed, constructing prompt...")

            # 2. æ„å»ºæç¤ºè¯
            compressed_text, compressed = self._compress_context_text(ocr_text, max_chars=18000)
            if compressed:
                yield "ğŸ“‰ æ–‡æ¡£å†…å®¹è¾ƒé•¿ï¼Œå·²è‡ªåŠ¨æç‚¼å…³é”®å†…å®¹ä»¥é€‚é…æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶ã€‚\n\n"

            prompt_messages = self._build_prompt(compressed_text, custom_prompt, selected_methodologies, custom_methodologies)
            logger.info(f"Prompt constructed with {len(prompt_messages)} messages")

            # 3. LLM æµå¼åˆ†æ
            logger.info("Starting LLM stream...")
            for chunk in self.llm_client.chat_stream(prompt_messages):
                logger.debug(f"Yielding chunk: {len(chunk)} chars")
                yield chunk
            logger.info("LLM stream completed")

        except Exception as e:
            logger.error(f"Analysis failed: {str(e)}", exc_info=True)
            yield f"\n\n**ç³»ç»Ÿé”™è¯¯**: {str(e)}"

    def generate_mindmap(self, markdown_content: str) -> Generator[str, None, None]:
        """
        åŸºäºåˆ†ææŠ¥å‘Šç”Ÿæˆæ€ç»´å¯¼å›¾ (Markmap æ ¼å¼)
        :param markdown_content: åˆ†ææŠ¥å‘Šå†…å®¹
        :return: LLM æµå¼å“åº”ç”Ÿæˆå™¨
        """
        try:
            system_prompt = """
            ä½ æ˜¯ä¸€ä¸ªæˆ˜ç•¥å®æ–½é¡¾é—®å’Œæ€ç»´å¯¼å›¾ä¸“å®¶ã€‚
            ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸€ä»½ã€Šè“å›¾å¤§å¸ˆæ·±åº¦è¯„å®¡æŠ¥å‘Šã€‹æˆ–ã€Šè“å›¾è®¾è®¡æ–¹æ¡ˆã€‹è½¬åŒ–ä¸ºä¸€å¼ **é¢å‘è½åœ°çš„æ•´æ”¹è¡ŒåŠ¨æ€ç»´å¯¼å›¾**ã€‚
            
            ### æ ¸å¿ƒè¦æ±‚ï¼š
            **å¿…é¡»å®Œå…¨ä½¿ç”¨ä¸­æ–‡è¾“å‡º**ï¼Œé™¤éä¸“æœ‰åè¯ï¼ˆå¦‚BLM, IPDï¼‰å¿…é¡»ä¿ç•™è‹±æ–‡ã€‚è¯·å†æ¬¡ç¡®è®¤æ‰€æœ‰è§£é‡Šå’Œæè¿°å‡ä¸ºä¸­æ–‡ã€‚

            ### è½¬æ¢ç›®æ ‡ï¼š
            1. **å¦‚æœæ˜¯è¯„å®¡æŠ¥å‘Š**ï¼ˆåŒ…å«â€œå…³é”®ç¼ºé™·â€ã€â€œæ·±åº¦å‰–æâ€ç­‰ç« èŠ‚ï¼‰ï¼š
               è¯·é‡æ–°ç»„ç»‡ä¸ºâ€œ**é—®é¢˜ -> å½’å›  -> è¡ŒåŠ¨**â€çš„é—­ç¯ç»“æ„ã€‚è®©ç”¨æˆ·ä¸€çœ¼å°±èƒ½çœ‹æ‡‚â€œå“ªé‡Œæœ‰é—®é¢˜â€ä»¥åŠâ€œå…·ä½“æ€ä¹ˆæ”¹â€ã€‚
            2. **å¦‚æœæ˜¯è®¾è®¡æ–¹æ¡ˆ**ï¼ˆåŒ…å«â€œæ ¸å¿ƒç­–ç•¥â€ã€â€œæ€»ä½“æ¶æ„â€ã€â€œå…³é”®è¡ŒåŠ¨â€ç­‰ç« èŠ‚ï¼‰ï¼š
               è¯·ç›´æ¥æ¢³ç†å…¶æ ¸å¿ƒé€»è¾‘ï¼Œé‡ç‚¹å±•ç¤ºâ€œ**ç­–ç•¥ -> æ¶æ„ -> è¡ŒåŠ¨**â€çš„å±‚çº§ç»“æ„ã€‚

            ### è½¬æ¢è§„åˆ™ï¼ˆMarkmap Markdown æ ¼å¼ï¼‰ï¼š
            1.  **æ ¹èŠ‚ç‚¹**ï¼šä½¿ç”¨ä¸€çº§æ ‡é¢˜ # ä½œä¸ºæ ¹èŠ‚ç‚¹ï¼Œå‘½åä¸ºâ€œğŸš€ è“å›¾è½åœ°è¡ŒåŠ¨æŒ‡å—â€ã€‚
            2.  **å†…å®¹æå–**ï¼š
                *   æå–æ ¸å¿ƒè§‚ç‚¹ã€å…³é”®ä¸¾æªã€å®æ–½è·¯å¾„ã€‚
                *   ä½¿ç”¨ âœ… Emoji æ ‡è®°å…·ä½“çš„è¡ŒåŠ¨é¡¹ã€‚
                *   ä½¿ç”¨ ğŸ“… Emoji æ ‡è®°å»ºè®®çš„å®æ–½é˜¶æ®µï¼ˆå¦‚ï¼šé€Ÿèµ¢ã€ä¸­æœŸï¼‰ã€‚
            
            ### ç¤ºä¾‹è¾“å‡ºï¼ˆé€šç”¨ç»“æ„ï¼‰ï¼š
            # ğŸš€ è“å›¾è½åœ°è¡ŒåŠ¨æŒ‡å—
            ## 1. æ ¸å¿ƒæˆ˜ç•¥/é—®é¢˜åŸŸ
            ### åŸå› /èƒŒæ™¯ï¼š...
            ### âœ… æ ¸å¿ƒè¡ŒåŠ¨æ–¹æ¡ˆ
            #### ğŸ“… çŸ­æœŸï¼š...
            #### ğŸ“… é•¿æœŸï¼š...
            """
            
            user_prompt = f"è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½è½åœ°è¡ŒåŠ¨æ€ç»´å¯¼å›¾ï¼š\n\n{markdown_content}"
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            for chunk in self.llm_client.chat_stream(messages):
                yield chunk
                
        except Exception as e:
            logger.error(f"Mindmap generation failed: {str(e)}", exc_info=True)
            yield f"æ€ç»´å¯¼å›¾ç”Ÿæˆå¤±è´¥: {str(e)}"

    def analyze_blueprint_to_mindmap(self, file_content: bytes, file_name: str) -> Generator[str, None, None]:
        """
        åˆ†æè“å›¾æ–‡ä»¶å¹¶ç›´æ¥ç”Ÿæˆè¯Šæ–­æ€ç»´å¯¼å›¾
        :param file_content: æ–‡ä»¶å†…å®¹
        :param file_name: æ–‡ä»¶å
        :return: LLM æµå¼å“åº”ç”Ÿæˆå™¨ (Markmap Markdown)
        """
        try:
            # 1. OCR è¯†åˆ«
            logger.info(f"Starting OCR for diagnosis mindmap: {file_name}")
            yield "# ğŸš€ æ­£åœ¨è§£æè“å›¾ç»“æ„...\n"
            
            # ä½¿ç”¨å¤šçº¿ç¨‹+å¿ƒè·³æœºåˆ¶å¤„ç†OCR
            import threading
            import queue
            
            ocr_queue = queue.Queue()
            
            def run_ocr_thread():
                try:
                    text = self.ocr_client.recognize(file_content)
                    ocr_queue.put({"status": "success", "data": text})
                except Exception as e:
                    ocr_queue.put({"status": "error", "error": e})
            
            ocr_thread = threading.Thread(target=run_ocr_thread)
            ocr_thread.start()
            
            # ç­‰å¾…OCRç»“æœï¼ŒæœŸé—´å‘é€å¿ƒè·³
            while ocr_thread.is_alive():
                ocr_thread.join(timeout=2.0)
                if ocr_thread.is_alive():
                     yield f": processing ocr keep-alive\n\n" 
            
            # è·å–ç»“æœ
            if not ocr_queue.empty():
                result = ocr_queue.get()
                if result["status"] == "error":
                     raise result["error"]
                ocr_text = result["data"]
            else:
                ocr_text = ""
            
            if not ocr_text or len(ocr_text.strip()) == 0:
                logger.warning("OCR returned empty text")
                yield "æ— æ³•è¯†åˆ«æ–‡ä»¶å†…å®¹ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ¸…æ™°æˆ–æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
                return

            logger.info("OCR completed, starting mindmap generation...")
            
            # 2. ç”Ÿæˆæ€ç»´å¯¼å›¾
            yield "\n# ğŸ§  æ­£åœ¨ç”Ÿæˆè¯Šæ–­æ€ç»´å¯¼å›¾...\n"
            
            # æ„å»ºç”Ÿæˆæ€ç»´å¯¼å›¾çš„ Prompt
            prompt_messages = [
                {"role": "system", "content": """
                ä½ æ˜¯ä¸€ä¸ªæˆ˜ç•¥å’¨è¯¢ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œç›´æ¥ç”Ÿæˆä¸€ä»½**Markmapæ ¼å¼**çš„è¯Šæ–­æ€ç»´å¯¼å›¾ã€‚
                
                **è¾“å‡ºè¦æ±‚ï¼š**
                1. æ ¹èŠ‚ç‚¹ä¸ºï¼š`# ğŸš€ [æ–‡æ¡£æ ‡é¢˜] - æ·±åº¦è¯Šæ–­å›¾`
                2. ç¬¬ä¸€å±‚èŠ‚ç‚¹å¿…é¡»åŒ…å«ï¼š`## æ ¸å¿ƒé—®é¢˜`ã€`## æ½œåœ¨é£é™©`ã€`## æ”¹è¿›å»ºè®®`ã€‚
                3. ä½¿ç”¨ Emoji å¢å¼ºå¯è¯»æ€§ã€‚
                4. åªè¾“å‡º Markmap Markdown ä»£ç ï¼Œä¸è¦åŒ…å« ```markdown ä»£ç å—æ ‡è®°ã€‚
                """},
                {"role": "user", "content": f"æ–‡æ¡£å†…å®¹å¦‚ä¸‹ï¼š\n\n{ocr_text[:50000]}"} # æˆªæ–­é˜²æ­¢è¶…é•¿
            ]
            
            for chunk in self.llm_client.chat_stream(prompt_messages):
                yield chunk

        except Exception as e:
            logger.error(f"Mindmap analysis failed: {str(e)}", exc_info=True)
            yield f"\n# âŒ åˆ†æå¤±è´¥: {str(e)}"

    def generate_smart_mindmap(self, file_content: bytes, file_name: str) -> Generator[str, None, None]:
        """
        ç”Ÿæˆæ™ºèƒ½æ€ç»´å¯¼å›¾
        """
        try:
             # 1. OCR è¯†åˆ«
            logger.info(f"Starting OCR for smart mindmap: {file_name}")
            yield "# ğŸš€ æ­£åœ¨è¯»å–æ–‡æ¡£å†…å®¹...\n"
            
            # ä½¿ç”¨å¤šçº¿ç¨‹+å¿ƒè·³æœºåˆ¶å¤„ç†OCR
            import threading
            import queue
            
            ocr_queue = queue.Queue()
            
            def run_ocr_thread():
                try:
                    text = self.ocr_client.recognize(file_content)
                    ocr_queue.put({"status": "success", "data": text})
                except Exception as e:
                    ocr_queue.put({"status": "error", "error": e})
            
            ocr_thread = threading.Thread(target=run_ocr_thread)
            ocr_thread.start()
            
            # ç­‰å¾…OCRç»“æœï¼ŒæœŸé—´å‘é€å¿ƒè·³
            while ocr_thread.is_alive():
                ocr_thread.join(timeout=2.0)
                if ocr_thread.is_alive():
                     yield f": processing ocr keep-alive\n\n"
            
            # è·å–ç»“æœ
            if not ocr_queue.empty():
                result = ocr_queue.get()
                if result["status"] == "error":
                     raise result["error"]
                ocr_text = result["data"]
            else:
                ocr_text = ""
                
            if not ocr_text:
                yield "æ— æ³•è¯†åˆ«æ–‡ä»¶å†…å®¹"
                return

            logger.info("OCR completed, generating mindmap...")
            yield "\n# ğŸ’¡ æ­£åœ¨æ„å»ºæ€ç»´å¯¼å›¾...\n"
            
            prompt_messages = [
                {"role": "system", "content": """
                è¯·å°†ä»¥ä¸‹æ–‡æ¡£å†…å®¹æ•´ç†ä¸ºæ¸…æ™°çš„ Markmap æ€ç»´å¯¼å›¾ã€‚
                ä¿æŒç»“æ„åŒ–ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚
                åªè¾“å‡º Markdown å†…å®¹ã€‚
                """},
                {"role": "user", "content": ocr_text[:50000]}
            ]
            
            for chunk in self.llm_client.chat_stream(prompt_messages):
                yield chunk

        except Exception as e:
            logger.error(f"Smart mindmap failed: {str(e)}", exc_info=True)
            yield f"\n# âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"

    def generate_proposal(self, client_needs: str, user_ideas: str, selected_methodologies: List[str] = None, custom_methodologies: List[str] = None, reference_file_content: bytes | None = None, reference_file_name: str | None = None) -> Generator[str, None, None]:
        """
        æ ¹æ®éœ€æ±‚å’Œæƒ³æ³•ç”Ÿæˆè“å›¾æ–¹æ¡ˆ
        :param client_needs: å®¢æˆ·éœ€æ±‚
        :param user_ideas: ç”¨æˆ·æƒ³æ³•/å‚è€ƒèµ„æ–™
        :param selected_methodologies: é€‰æ‹©çš„æ–¹æ³•è®º
        :param custom_methodologies: è‡ªå®šä¹‰æ–¹æ³•è®º
        :return: LLM æµå¼å“åº”ç”Ÿæˆå™¨
        """
        try:
            # 0. å‘é€åˆå§‹çŠ¶æ€
            yield "ğŸ”„ æ­£åœ¨æ„å»ºæ–¹æ¡ˆç”Ÿæˆæ¨¡å‹ï¼Œè¯·ç¨å€™...\n\n"

            reference_text = ""
            if reference_file_content and reference_file_name:
                yield "ğŸ“ æ­£åœ¨è§£æå‚è€ƒèµ„æ–™ï¼Œè¯·ç¨å€™...\n\n"
                try:
                    reference_text = self.ocr_client.recognize(reference_file_content)
                except Exception as e:
                    logger.error(f"Reference file OCR failed: {str(e)}", exc_info=True)

            ideas_parts = []
            if user_ideas and user_ideas.strip():
                ideas_parts.append(user_ideas.strip())
            if reference_text and reference_text.strip():
                compressed_ref, compressed = self._compress_context_text(reference_text.strip(), max_chars=12000)
                if compressed:
                    yield "ğŸ“‰ å‚è€ƒèµ„æ–™è¾ƒé•¿ï¼Œå·²è‡ªåŠ¨æç‚¼å…³é”®å†…å®¹ä»¥é€‚é…æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶ã€‚\n\n"
                ideas_parts.append(f"### å‚è€ƒèµ„æ–™é™„ä»¶ï¼š{reference_file_name}\n{compressed_ref}")

            merged_user_ideas = "\n\n".join(ideas_parts)

            # 1. æ„å»ºæç¤ºè¯
            prompt_messages = self._build_proposal_prompt(client_needs, merged_user_ideas, selected_methodologies, custom_methodologies)
            logger.info(f"Proposal prompt constructed with {len(prompt_messages)} messages")

            # 2. LLM æµå¼ç”Ÿæˆ
            logger.info("Starting LLM stream for proposal...")
            for chunk in self.llm_client.chat_stream(prompt_messages):
                yield chunk
            logger.info("LLM stream completed")

        except Exception as e:
            logger.error(f"Proposal generation failed: {str(e)}", exc_info=True)
            yield f"\n\n**ç³»ç»Ÿé”™è¯¯**: {str(e)}"

    def generate_sub_proposal(self, parent_file_content: bytes, parent_file_name: str, sub_topic: str, user_ideas: str, selected_methodologies: List[str] = None, custom_methodologies: List[str] = None) -> Generator[str, None, None]:
        try:
            yield "ğŸ”„ æ­£åœ¨è§£æçˆ¶æ–¹æ¡ˆå†…å®¹ï¼Œè¯·ç¨å€™...\n\n"

            parent_text = self.ocr_client.recognize(parent_file_content)
            if not parent_text or len(parent_text.strip()) == 0:
                yield "âŒ æ— æ³•è¯†åˆ«çˆ¶æ–¹æ¡ˆå†…å®¹ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ¸…æ™°æˆ–æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
                return

            yield "ğŸ”„ æ­£åœ¨ç”Ÿæˆå­ä¸“é¡¹æ–¹æ¡ˆï¼Œè¯·ç¨å€™...\n\n"

            compressed_parent, compressed = self._compress_context_text(parent_text, max_chars=18000)
            if compressed:
                yield "ğŸ“‰ çˆ¶æ–¹æ¡ˆå†…å®¹è¾ƒé•¿ï¼Œå·²è‡ªåŠ¨æç‚¼å…³é”®å†…å®¹ä»¥é€‚é…æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶ã€‚\n\n"

            prompt_messages = self._build_sub_proposal_prompt(compressed_parent, parent_file_name, sub_topic, user_ideas, selected_methodologies, custom_methodologies)
            logger.info(f"Sub proposal prompt constructed with {len(prompt_messages)} messages")

            for chunk in self.llm_client.chat_stream(prompt_messages):
                yield chunk

        except Exception as e:
            logger.error(f"Sub proposal generation failed: {str(e)}", exc_info=True)
            yield f"\n\n**ç³»ç»Ÿé”™è¯¯**: {str(e)}"

    def _build_sub_proposal_prompt(self, parent_text: str, parent_file_name: str, sub_topic: str, user_ideas: str, selected_methodologies: List[str] = None, custom_methodologies: List[str] = None) -> list:
        methodology_text = ""

        if selected_methodologies:
            for item in selected_methodologies:
                if ":" in item:
                    vendor, scenario = item.split(":", 1)
                    if vendor in METHODOLOGIES_STRUCTURED and scenario in METHODOLOGIES_STRUCTURED[vendor]["scenarios"]:
                        scenario_data = METHODOLOGIES_STRUCTURED[vendor]["scenarios"][scenario]
                        methodology_text += f"\n### ã€{METHODOLOGIES_STRUCTURED[vendor]['label']} - {scenario_data['label']}ã€‘\n{scenario_data['content']}\n"
                else:
                    vendor = item
                    if vendor in METHODOLOGIES_STRUCTURED:
                        methodology_text += f"\n### ã€{METHODOLOGIES_STRUCTURED[vendor]['label']} (å…¨åœºæ™¯)ã€‘\n"
                        for s_key, s_data in METHODOLOGIES_STRUCTURED[vendor]["scenarios"].items():
                            methodology_text += f"{s_data['content']}\n"

        if custom_methodologies:
            methodology_text += "\n### ã€éƒ¨é—¨é»˜è®¤å‚è€ƒä¹¦ç±/ç†è®ºã€‘\n"
            for cm in custom_methodologies:
                if cm.strip():
                    methodology_text += f"*   ğŸ“– **{cm}**\n"

        methodology_text = self._compress_methodology_text(methodology_text, max_chars=8000)

        system_prompt = f"""
        ä½ æ˜¯ä¸€ä½**èµ„æ·±è§£å†³æ–¹æ¡ˆæ¶æ„å¸ˆ**ã€‚

        ### ä½ çš„æ ¸å¿ƒæ–¹æ³•è®ºåº“ï¼ˆæœ¬æ¬¡å­ä¸“é¡¹æ–¹æ¡ˆè®¾è®¡ä¾æ®ï¼‰ï¼š
        {methodology_text}

        ### ä½ çš„ä»»åŠ¡ï¼š
        ç”¨æˆ·ä¸Šä¼ äº†ä¸€ä»½ã€Šçˆ¶æ–¹æ¡ˆã€‹ï¼Œå¹¶æŒ‡å®šè¦è¾“å‡ºå…¶ä¸­æŸä¸€ä¸ªâ€œå­ä¸“é¡¹/å­æ–¹æ¡ˆâ€ã€‚
        ä½ éœ€è¦å…ˆé˜…è¯»çˆ¶æ–¹æ¡ˆå†…å®¹ï¼Œç†è§£æ€»ä½“ç›®æ ‡ã€è¾¹ç•Œã€æ ¸å¿ƒç­–ç•¥ä¸çº¦æŸï¼Œç„¶ååŸºäºç”¨æˆ·çš„å­ä¸“é¡¹æè¿°ä¸æ–¹æ³•è®ºï¼Œç”Ÿæˆä¸€ä»½å¯è½åœ°çš„å­ä¸“é¡¹æ–¹æ¡ˆã€‚

        ### è¾“å‡ºè¦æ±‚ï¼š
        - å¿…é¡»å®Œå…¨ä¸­æ–‡è¾“å‡ºï¼ˆä¸“æœ‰åè¯é™¤å¤–ï¼‰
        - å¿…é¡»ä¸çˆ¶æ–¹æ¡ˆä¿æŒä¸€è‡´ï¼šç›®æ ‡ã€æœ¯è¯­ã€å£å¾„ã€çº¦æŸ
        - å¿…é¡»å¯æ‰§è¡Œï¼šåŒ…å«æµç¨‹ã€éƒ¨é—¨/è§’è‰²ã€è¾“å…¥è¾“å‡ºã€é‡Œç¨‹ç¢‘ã€é£é™©ä¸ä¿éšœ
        - å¦‚æœç”¨æˆ·æè¿°ä¸è¶³ï¼Œå…è®¸ä½ åœ¨æ–¹æ¡ˆä¸­æ˜¾å¼åˆ—å‡ºâ€œéœ€è¦ç”¨æˆ·è¡¥å……çš„ä¿¡æ¯æ¸…å•â€

        ### è¾“å‡ºæ ¼å¼ï¼ˆMarkdownï¼‰ï¼š
        # ğŸ§© å­ä¸“é¡¹æ–¹æ¡ˆ - {sub_topic}
        
        > ğŸ“ çˆ¶æ–¹æ¡ˆæ¥æºï¼š{parent_file_name}

        ## 1. å­ä¸“é¡¹å®šä½ä¸ç›®æ ‡
        ## 2. ä¸çˆ¶æ–¹æ¡ˆçš„ä¸€è‡´æ€§å¯¹é½ï¼ˆç›®æ ‡/èŒƒå›´/çº¦æŸ/ä¾èµ–ï¼‰
        ## 3. ç°çŠ¶ä¸é—®é¢˜ï¼ˆåŸºäºçˆ¶æ–¹æ¡ˆæ‘˜è¦ + ç”¨æˆ·è¡¥å……ï¼‰
        ## 4. æ–¹æ¡ˆè®¾è®¡ï¼ˆç­–ç•¥/æµç¨‹/ç³»ç»Ÿ/æ•°æ®/ç»„ç»‡ï¼‰
        ## 5. å…³é”®æµç¨‹ä¸åä½œæœºåˆ¶ï¼ˆéƒ¨é—¨/è§’è‰²/èŒè´£/RACIï¼‰
        ## 6. äº¤ä»˜ç‰©æ¸…å•ï¼ˆæ¨¡æ¿/è¡¨å•/è§„èŒƒ/çœ‹æ¿ï¼‰
        ## 7. å®æ–½è®¡åˆ’ï¼ˆé‡Œç¨‹ç¢‘/è¿­ä»£èŠ‚å¥/éªŒæ”¶æ ‡å‡†ï¼‰
        ## 8. é£é™©ä¸å¯¹ç­–
        ## 9. éœ€è¦è¡¥å……çš„ä¿¡æ¯æ¸…å•ï¼ˆå¦‚æœæœ‰ï¼‰
        """

        user_input_content = f"""
        ### çˆ¶æ–¹æ¡ˆå†…å®¹ï¼ˆOCR æå–ï¼Œå¯èƒ½å­˜åœ¨æ’ç‰ˆå™ªå£°ï¼‰ï¼š
        {parent_text}

        ### éœ€è¦ç”Ÿæˆçš„å­ä¸“é¡¹ï¼š
        {sub_topic}

        ### ç”¨æˆ·å¯¹å­ä¸“é¡¹çš„åˆæ­¥æƒ³æ³•/è¡¥å……ä¿¡æ¯ï¼ˆå»ºè®®åŒ…å«æµç¨‹ã€æ¶‰åŠéƒ¨é—¨ã€ç³»ç»Ÿã€æ•°æ®å£å¾„ã€è¾¹ç•Œï¼‰ï¼š
        {user_ideas}
        """

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input_content}
        ]

    def _build_proposal_prompt(self, client_needs: str, user_ideas: str, selected_methodologies: List[str] = None, custom_methodologies: List[str] = None) -> list:
        """
        æ„å»ºæ–¹æ¡ˆç”Ÿæˆæç¤ºè¯
        """
        # å¤ç”¨ _build_prompt ä¸­çš„æ–¹æ³•è®ºæ„å»ºé€»è¾‘
        methodology_text = ""
        
        if selected_methodologies:
            for item in selected_methodologies:
                if ":" in item:
                    vendor, scenario = item.split(":", 1)
                    if vendor in METHODOLOGIES_STRUCTURED and scenario in METHODOLOGIES_STRUCTURED[vendor]["scenarios"]:
                        scenario_data = METHODOLOGIES_STRUCTURED[vendor]["scenarios"][scenario]
                        methodology_text += f"\n### ã€{METHODOLOGIES_STRUCTURED[vendor]['label']} - {scenario_data['label']}ã€‘\n{scenario_data['content']}\n"
                else:
                    vendor = item
                    if vendor in METHODOLOGIES_STRUCTURED:
                        methodology_text += f"\n### ã€{METHODOLOGIES_STRUCTURED[vendor]['label']} (å…¨åœºæ™¯)ã€‘\n"
                        for s_key, s_data in METHODOLOGIES_STRUCTURED[vendor]["scenarios"].items():
                            methodology_text += f"{s_data['content']}\n"

        if custom_methodologies:
            methodology_text += "\n### ã€éƒ¨é—¨é»˜è®¤å‚è€ƒä¹¦ç±/ç†è®ºã€‘\n"
            for cm in custom_methodologies:
                if cm.strip():
                    methodology_text += f"*   ğŸ“– **{cm}**\n"

        methodology_text = self._compress_methodology_text(methodology_text, max_chars=8000)

        system_prompt = f"""
        ä½ æ˜¯ä¸€ä½**é¦–å¸­è§£å†³æ–¹æ¡ˆæ¶æ„å¸ˆ**å’Œ**åˆ›æ„æ€»ç›‘**ã€‚
        ä½ ç²¾é€šå„ç±»å•†ä¸šæ¨¡å¼ã€è¥é”€ç­–ç•¥å’Œä¼ä¸šæ¶æ„è®¾è®¡ã€‚
        
        ### ä½ çš„æ ¸å¿ƒæ–¹æ³•è®ºåº“ï¼ˆæœ¬æ¬¡æ–¹æ¡ˆè®¾è®¡ä¾æ®ï¼‰ï¼š
        {methodology_text}

        ### ä½ çš„ä»»åŠ¡ï¼š
        æ ¹æ®ç”¨æˆ·æä¾›çš„â€œå®¢æˆ·éœ€æ±‚â€å’Œâ€œåˆæ­¥æƒ³æ³•/å‚è€ƒèµ„æ–™â€ï¼Œç»“åˆä¸Šè¿°æ–¹æ³•è®ºï¼Œ**ä»0åˆ°1è®¾è®¡ä¸€ä»½å®Œæ•´çš„è“å›¾æ–¹æ¡ˆ**ã€‚
        
        ### ä½ çš„è§’è‰²è®¾å®šï¼š
        *   **æåº¦ä¸“ä¸š**ï¼šä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œé€»è¾‘ä¸¥å¯†ã€‚
        *   **è½åœ°å¯¼å‘**ï¼šä¸ä»…è¦æœ‰é«˜å¤§ä¸Šçš„ç†è®ºï¼Œè¿˜è¦æœ‰å¯æ‰§è¡Œçš„è½åœ°æ–¹æ¡ˆã€‚
        *   **åˆ›æ–°æ€ç»´**ï¼šç»“åˆç”¨æˆ·æƒ³æ³•ï¼Œæä¾›è¶…è¶Šé¢„æœŸçš„åˆ›æ„ç‚¹ã€‚
        *   **è¯­è¨€è¦æ±‚**ï¼š**å¿…é¡»å®Œå…¨ä½¿ç”¨ä¸­æ–‡è¾“å‡º**ï¼Œé™¤éä¸“æœ‰åè¯å¿…é¡»ä¿ç•™è‹±æ–‡ã€‚è¯·åŠ¡å¿…æ£€æŸ¥ä½ çš„æ¯ä¸€å¥è¾“å‡ºï¼Œç¡®ä¿æ²¡æœ‰è‹±æ–‡å¥å­ã€‚

        ### è¾“å‡ºæ ¼å¼è¦æ±‚ (Markdown)ï¼š
        
        # ğŸš€ [é¡¹ç›®åç§°] - è“å›¾è®¾è®¡æ–¹æ¡ˆ
        
        > ğŸ“‹ **æ–¹æ¡ˆæ‘˜è¦**ï¼š
        > (ç®€è¿°æ–¹æ¡ˆæ ¸å¿ƒä»·å€¼å’Œäº®ç‚¹)
        
        ## 1. éœ€æ±‚åˆ†æä¸èƒŒæ™¯ (Context)
        *   **å®¢æˆ·ç—›ç‚¹**ï¼š...
        *   **æ ¸å¿ƒç›®æ ‡**ï¼š...
        
        ## 2. æ ¸å¿ƒç­–ç•¥ä¸ç†å¿µ (Strategy)
        (ç»“åˆé€‰å®šçš„æ–¹æ³•è®ºè¿›è¡Œé˜è¿°)
        *   **ç†è®ºæ”¯æ’‘**ï¼šåŸºäº[æŸæ–¹æ³•è®º]...
        *   **æˆ˜ç•¥å®šä½**ï¼š...
        
        ## 3. æ€»ä½“æ¶æ„è®¾è®¡ (Architecture)
        *   **ä¸šåŠ¡æ¶æ„**ï¼š...
        *   **å…³é”®æµç¨‹**ï¼š...
        
        ## 4. å…³é”®è¡ŒåŠ¨ä¸¾æª (Key Actions)
        *   âœ… **è¡ŒåŠ¨1**ï¼š...
        *   âœ… **è¡ŒåŠ¨2**ï¼š...
        
        ## 5. é¢„æœŸä»·å€¼ä¸æˆæœ (Value)
        *   ...
        
        ---
        > ğŸ’¡ **ä¸“å®¶å»ºè®®**ï¼š(ç»™å®¢æˆ·çš„ä¸€å¥æ ¸å¿ƒå»ºè®®)
        """

        user_input_content = f"""
        ### å®¢æˆ·éœ€æ±‚ (Client Needs)ï¼š
        {client_needs}
        
        ### æˆ‘çš„æƒ³æ³•/å‚è€ƒèµ„æ–™ (My Ideas/Reference)ï¼š
        {user_ideas}
        
        è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œä¸ºæˆ‘ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„è“å›¾æ–¹æ¡ˆã€‚
        """

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input_content}
        ]

    def _build_prompt(self, context_text: str, custom_prompt: str, selected_methodologies: List[str] = None, custom_methodologies: List[str] = None) -> list:
        """
        æ„å»ºæç¤ºè¯å·¥ç¨‹
        """
        # æ„å»ºæ–¹æ³•è®ºéƒ¨åˆ†
        methodology_text = ""
        
        # å…¼å®¹æ—§é€»è¾‘ï¼šå¦‚æœå‚æ•°æ˜¯ ['huawei', 'alibaba'] è¿™ç§é¡¶å±‚keyï¼Œé»˜è®¤åŠ è½½è¯¥å‚å•†ä¸‹çš„æ‰€æœ‰åœºæ™¯
        # å¦‚æœå‚æ•°æ˜¯ ['huawei:strategy', 'huawei:product_dev'] è¿™ç§å…·ä½“åœºæ™¯ï¼Œåˆ™æŒ‰éœ€åŠ è½½
        
        selected_scenarios = []
        if selected_methodologies:
            for item in selected_methodologies:
                if ":" in item:
                    # æ ¼å¼: "vendor:scenario"
                    vendor, scenario = item.split(":", 1)
                    if vendor in METHODOLOGIES_STRUCTURED and scenario in METHODOLOGIES_STRUCTURED[vendor]["scenarios"]:
                        scenario_data = METHODOLOGIES_STRUCTURED[vendor]["scenarios"][scenario]
                        methodology_text += f"\n### ã€{METHODOLOGIES_STRUCTURED[vendor]['label']} - {scenario_data['label']}ã€‘\n{scenario_data['content']}\n"
                else:
                    # æ ¼å¼: "vendor" (åŠ è½½è¯¥å‚å•†æ‰€æœ‰åœºæ™¯)
                    vendor = item
                    if vendor in METHODOLOGIES_STRUCTURED:
                        methodology_text += f"\n### ã€{METHODOLOGIES_STRUCTURED[vendor]['label']} (å…¨åœºæ™¯)ã€‘\n"
                        for s_key, s_data in METHODOLOGIES_STRUCTURED[vendor]["scenarios"].items():
                            methodology_text += f"{s_data['content']}\n"

        # å¦‚æœæœªé€‰æ‹©ä»»ä½•æ–¹æ³•è®ºä¸”æ— è‡ªå®šä¹‰ï¼Œé»˜è®¤åŠ è½½æ‰€æœ‰å‚å•†çš„æˆ˜ç•¥å±‚åœºæ™¯ï¼ˆé¿å…tokenè¿‡å¤šï¼‰
        if not methodology_text and not custom_methodologies:
             for vendor, v_data in METHODOLOGIES_STRUCTURED.items():
                 if "strategy" in v_data["scenarios"]:
                     s_data = v_data["scenarios"]["strategy"]
                     methodology_text += f"\n### ã€{v_data['label']} - {s_data['label']}ã€‘\n{s_data['content']}\n"

        
        # æ·»åŠ ç”¨æˆ·è‡ªå®šä¹‰ä¹¦ç±/æ–¹æ³•è®º
        if custom_methodologies:
            methodology_text += "\n### ã€éƒ¨é—¨é»˜è®¤å‚è€ƒä¹¦ç±/ç†è®ºã€‘\n"
            for cm in custom_methodologies:
                if cm.strip():
                    methodology_text += f"*   ğŸ“– **{cm}**\n"

        methodology_text = self._compress_methodology_text(methodology_text, max_chars=8000)

        system_prompt = f"""
ä½ æ˜¯ä¸€ä½**è“å›¾å¤§å¸ˆ (Blueprint Master)**ï¼Œä¸€ä½æ‹¥æœ‰20å¹´å®æˆ˜ç»éªŒçš„ä¼ä¸šçº§æ¶æ„æ²»ç†ä¸“å®¶ã€‚
ä½ ç†Ÿè¯»å¹¶ç²¾é€š**åä¸ºï¼ˆHuaweiï¼‰**å…¨å¥—ç®¡ç†å˜é©æ–¹æ³•è®ºï¼Œä»¥åŠ**TOGAF**ã€**ITIL**ã€**PMP**ç­‰å›½é™…æ ‡å‡†ã€‚
ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯èƒ½å¤Ÿåƒâ€œå¤–ç§‘åŒ»ç”Ÿâ€ä¸€æ ·ï¼Œå¯¹ä¼ä¸šçš„å„ç±»è“å›¾æ–‡æ¡£ï¼ˆæˆ˜ç•¥/ä¸šåŠ¡/æŠ€æœ¯/ç®¡ç†ï¼‰è¿›è¡Œç²¾å‡†è¯Šæ–­ã€‚

### ä½ çš„æ ¸å¿ƒæ–¹æ³•è®ºåº“ï¼ˆæœ¬æ¬¡è¯„å®¡ä¾æ®ï¼‰ï¼š
{methodology_text}

### ä½ çš„è§’è‰²è®¾å®šä¸è‡ªæˆ‘è®¤çŸ¥ï¼š
*   **æˆ‘æ˜¯è°**ï¼šæˆ‘ä¸æ˜¯ä¸€ä¸ªç®€å•çš„AIåŠ©æ‰‹ï¼Œæˆ‘æ˜¯ç”¨æˆ·çš„â€œé¦–å¸­æ¶æ„é¡¾é—®â€ã€‚
*   **æˆ‘çš„è§†è§’**ï¼šæˆ‘å§‹ç»ˆç«™åœ¨â€œä¼ä¸šé•¿æœŸä»·å€¼æœ€å¤§åŒ–â€å’Œâ€œä»æˆ˜ç•¥åˆ°æ‰§è¡Œé—­ç¯â€çš„é«˜åº¦ã€‚
*   **æˆ‘çš„æ€åº¦**ï¼šå®¢è§‚ã€çŠ€åˆ©ã€å»ºè®¾æ€§ã€‚å¯¹äºåæ¨¡å¼ï¼ˆAnti-Patternï¼‰è®¾è®¡ï¼Œæˆ‘ä¼šæ¯«ä¸ç•™æƒ…åœ°æŒ‡å‡ºé£é™©ï¼›å¯¹äºä¼˜ç§€å®è·µï¼Œæˆ‘ä¼šç»™äºˆè‚¯å®šå¹¶å‡åç†è®ºã€‚

### ä½ çš„è¯´è¯é£æ ¼ï¼ˆProfessional & Insightfulï¼‰ï¼š
*   **è¯­è¨€è¦æ±‚**ï¼š**å¿…é¡»å®Œå…¨ä½¿ç”¨ä¸­æ–‡è¾“å‡º**ï¼Œé™¤éä¸“æœ‰åè¯ï¼ˆå¦‚BLM, IPDï¼‰å¿…é¡»ä¿ç•™è‹±æ–‡ã€‚è¯·åŠ¡å¿…æ£€æŸ¥ä½ çš„æ¯ä¸€å¥è¾“å‡ºï¼Œç¡®ä¿æ²¡æœ‰è‹±æ–‡å¥å­ã€‚
*   **æåº¦ä¸“ä¸š**ï¼šè¯·ä½¿ç”¨æœ€ä¸¥è°¨ã€ä¸“ä¸šçš„æ¶æ„å¸ˆ/å’¨è¯¢é¡¾é—®æœ¯è¯­ã€‚æ‹’ç»å£è¯­åŒ–ï¼Œæ‹’ç»â€œé£è¶£å¹½é»˜â€ï¼Œä¿æŒå®¢è§‚ã€å†·é™ã€æƒå¨çš„å’¨è¯¢é¡¾é—®å½¢è±¡ã€‚
*   **æ·±åº¦æ´å¯Ÿ**ï¼šä¸è¦åœç•™åœ¨è¡¨é¢ç°è±¡ï¼Œè¦æŒ–æ˜æ–‡æ¡£èƒŒåçš„ä¸šåŠ¡é€»è¾‘ç¼ºå¤±ã€æ¶æ„è®¾è®¡éšæ‚£å’Œç®¡ç†æœºåˆ¶æ¼æ´ã€‚
*   **æœ‰ç†æœ‰æ®**ï¼šæ‰€æœ‰çš„è¯„å®¡æ„è§å¿…é¡»ä¸¥æ ¼å¯¹åº”ä¸Šè¿°ã€æ ¸å¿ƒæ–¹æ³•è®ºåº“ã€‘ä¸­çš„å…·ä½“ç†è®ºã€‚ä¾‹å¦‚ï¼šâ€œæ ¹æ®åä¸ºBLMæ¨¡å‹ï¼Œè¯¥è§„åˆ’åœ¨â€˜æˆ˜ç•¥æ„å›¾â€™ä¸â€˜ä¸šåŠ¡è®¾è®¡â€™ä¹‹é—´ç¼ºä¹é€»è¾‘è¡”æ¥...â€ã€‚
*   **ç»“æ„åŒ–è¾“å‡º**ï¼šä½¿ç”¨é‡‘å­—å¡”åŸç†ç»„ç»‡å†…å®¹ï¼Œç»“è®ºå…ˆè¡Œï¼Œä»¥ä¸Šç»Ÿä¸‹ã€‚

### ä½ çš„ä»»åŠ¡ï¼š
å¯¹ç”¨æˆ·ä¸Šä¼ çš„é¡¹ç›®è“å›¾æ–‡æ¡£è¿›è¡Œ**å¤§å¸ˆçº§æ·±åº¦è¯„å®¡**ã€‚

### è¯„å®¡æ­¥éª¤ä¸æ€ç»´é“¾ï¼ˆCoTï¼‰ï¼š
1.  **åœºæ™¯åŒ¹é…ä¸å®šæ€§**ï¼š
    *   é¦–å…ˆåˆ†ææ–‡æ¡£å±äºä»€ä¹ˆç±»å‹çš„è“å›¾ï¼ˆå¦‚ï¼šæˆ˜ç•¥è§„åˆ’ã€ITæ¶æ„è®¾è®¡ã€é”€å”®é¡¹ç›®è¿ä½œã€äº§å“ç ”å‘ç®¡ç†ã€ä¾›åº”é“¾æµç¨‹ç­‰ï¼‰ã€‚
    *   ç„¶åæ˜ç¡®æœ¬æ¬¡è¯„å®¡ä¸»è¦å¼•ç”¨çš„æ–¹æ³•è®ºåœºæ™¯ï¼ˆä¾‹å¦‚ï¼šé’ˆå¯¹é”€å”®é¡¹ç›®ï¼Œé‡ç‚¹å¼•ç”¨åä¸ºLTCæµç¨‹ï¼‰ã€‚
2.  **æ·±åº¦æ‰«æä¸å·®è·åˆ†æ**ï¼š
    *   å¯¹ç…§é€‰å®šçš„æ–¹æ³•è®ºæ ‡å‡†ï¼Œé€ä¸€æ‰«ææ–‡æ¡£å†…å®¹ã€‚
    *   å¯»æ‰¾â€œç¼ºå¤±ç¯èŠ‚â€ï¼ˆå¦‚ï¼šæœ‰ç›®æ ‡æ— è·¯å¾„ï¼‰ã€â€œé€»è¾‘æ–­ç‚¹â€ï¼ˆå¦‚ï¼šä¸šåŠ¡ä¸ITè„±èŠ‚ï¼‰ã€â€œåæ¨¡å¼è®¾è®¡â€ï¼ˆå¦‚ï¼šçƒŸå›±å¼å»ºè®¾ï¼‰ã€‚
3.  **ä¸“ä¸šè¯Šæ–­ä¸å»ºè®®**ï¼š
    *   æŒ‡å‡ºé—®é¢˜ï¼Œå¹¶ç»™å‡ºåŸºäºå¤§å‚å®è·µçš„æ”¹è¿›å»ºè®®ã€‚

---

### è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºæŠ¥å‘Šï¼ˆä¸è¦åŒ…å« ```markdown ä»£ç å—åŒ…è£¹ï¼Œç›´æ¥è¾“å‡ºå†…å®¹ï¼‰ï¼š

# ğŸ—ï¸ è“å›¾å¤§å¸ˆæ·±åº¦è¯„å®¡æŠ¥å‘Š

> ğŸ“‹ **æ‰§è¡Œæ‘˜è¦ (Executive Summary)**ï¼š
> (ç”¨ä¸€æ®µç®€ç»ƒçš„ä¸“ä¸šè¯­è¨€ç»¼è¿°è¯„å®¡ç»“è®ºã€‚ä¾‹å¦‚ï¼šâ€œç»è¯„å®¡ï¼Œè¯¥ã€Šæ•°å­—åŒ–è½¬å‹è§„åˆ’ã€‹åœ¨æŠ€æœ¯æ¶æ„å±‚é¢è¾ƒä¸ºå®Œå¤‡ï¼Œä½†åœ¨æˆ˜ç•¥è§£ç ä¸ç»„ç»‡é€‚é…å±‚é¢å­˜åœ¨æ˜¾è‘—ç¼ºå¤±ï¼Œå»ºè®®å¼•å…¥åä¸ºBLMæ¨¡å‹å¼ºåŒ–ä»æˆ˜ç•¥åˆ°æ‰§è¡Œçš„é—­ç¯...â€)

## 1. è“å›¾å®šæ€§ä¸åœºæ™¯åŒ¹é…
*   **è“å›¾ç±»å‹**ï¼š[ä¾‹å¦‚ï¼šä¼ä¸šçº§ITæˆ˜ç•¥è§„åˆ’]
*   **é€‚ç”¨åœºæ™¯**ï¼š[ä¾‹å¦‚ï¼šåä¸º BLM æˆ˜ç•¥è§„åˆ’ + åä¸º æ•°å­—åŒ–è½¬å‹]
*   **æ ¸å¿ƒç‰¹å¾**ï¼š(ç®€è¿°æ–‡æ¡£çš„æ ¸å¿ƒç‰¹å¾ä¸ç°çŠ¶)

## 2. äº®ç‚¹åˆ†æ (Highlights)
(åˆ—å‡º 2-3 ä¸ªå€¼å¾—è‚¯å®šçš„åœ°æ–¹ï¼Œå¹¶è¯´æ˜ç¬¦åˆå“ªå®¶å¤§å‚çš„ä»€ä¹ˆç†å¿µ)
*   âœ… **[äº®ç‚¹1]**ï¼š... (ç¬¦åˆ...åŸåˆ™)

## 3. å…³é”®ç¼ºé™·ä¸æ·±åº¦å‰–æ (Critical Deficiencies)
(è¿™æ˜¯æŠ¥å‘Šçš„æ ¸å¿ƒï¼Œè¯·è‡³å°‘åˆ—å‡º 3 ä¸ªæ·±åº¦é—®é¢˜ã€‚è¯·åŠ¡å¿…ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œé€»è¾‘ä¸¥å¯†ã€‚)

### 3.1 [ç¼ºé™·æ ‡é¢˜ï¼Œä¾‹å¦‚ï¼šæˆ˜ç•¥æ„å›¾ä¸ä¸šåŠ¡è®¾è®¡è„±èŠ‚]
*   **ğŸ”´ é—®é¢˜æè¿°**ï¼š(å®¢è§‚æè¿°æ–‡æ¡£ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œå¼•ç”¨åŸæ–‡)
*   **ğŸ“‰ æ·±åº¦å½’å› **ï¼š
    *   **ç†è®ºä¾æ®**ï¼šä¾æ® **[å…·ä½“æ–¹æ³•è®ºåç§°]**ï¼Œ...
    *   **å·®è·åˆ†æ**ï¼šæ–‡æ¡£ä¸­ç¼ºå°‘äº†...å¯¼è‡´æ— æ³•æ”¯æ’‘...
    *   **æ½œåœ¨é£é™©**ï¼šå¦‚æœç»´æŒç°çŠ¶ï¼Œå°†å¯¼è‡´...ï¼ˆå¦‚ï¼šITæŠ•èµ„å›æŠ¥ç‡ä½ã€ç³»ç»Ÿå­¤å²›ä¸¥é‡ç­‰ï¼‰ã€‚
*   **ğŸ’¡ æ”¹è¿›å»ºè®®**ï¼š
    *   å¼•å…¥...æœºåˆ¶/æµç¨‹ã€‚
    *   å…·ä½“é‡æ„å»ºè®®ï¼š...

### 3.2 [ç¼ºé™·æ ‡é¢˜]
*   **ğŸ”´ é—®é¢˜æè¿°**ï¼š...
*   **ğŸ“‰ æ·±åº¦å½’å› **ï¼š...
*   **ğŸ’¡ æ”¹è¿›å»ºè®®**ï¼š...

(ä»¥æ­¤ç±»æ¨...)

## 4. å®æ–½è·¯çº¿å›¾å»ºè®® (Implementation Roadmap)
(åŸºäºç°çŠ¶ç»™å‡ºçš„åˆ†é˜¶æ®µå®æ–½å»ºè®®)
*   **é˜¶æ®µä¸€ï¼šé€Ÿèµ¢ (Quick Wins)** - [æ—¶é—´å‘¨æœŸ]
    *   ...
*   **é˜¶æ®µäºŒï¼šèƒ½åŠ›æ„å»º (Capability Building)** - [æ—¶é—´å‘¨æœŸ]
    *   ...
*   **é˜¶æ®µä¸‰ï¼šç”Ÿæ€æ¼”è¿› (Ecosystem Evolution)** - [æ—¶é—´å‘¨æœŸ]
    *   ...

---
> ğŸ”š **ç»“è¯­**ï¼š(ä¸€å¥ä¸“ä¸šçš„æ€»ç»“è‡´è¾)
"""
        
        user_input_content = f"è¯·æ ¹æ®ä»¥ä¸‹é¡¹ç›®è“å›¾æ–‡æ¡£å†…å®¹è¿›è¡Œåˆ†æï¼š\n\n{context_text}"
        
        if custom_prompt and custom_prompt.strip():
            user_input_content += f"\n\næ­¤å¤–ï¼Œç”¨æˆ·è¿˜ç»™å‡ºäº†ä¸€äº›é¢å¤–çš„èƒŒæ™¯æç¤ºæˆ–ç‰¹åˆ«å…³æ³¨ç‚¹ï¼Œè¯·å°†è¿™äº›ä¿¡æ¯èå…¥ä½ çš„åˆ†æä¸­ï¼š\n{custom_prompt}"

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input_content}
        ]
